{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import missingno as msno\n",
    "import pandas_profiling\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "#解决中文显示问题\n",
    "plt.rcParams[\"font.sans-serif\"] = [u\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "#解决图中负号问题\n",
    "plt.rcParams['axes.unicode_minus']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name=['id','target','card_type','netlong','owner_city','arpu','out_prdct_fee','prdct_fee','point_fee','myth_fee','brand','listing_date','listing_price','nettime','user_level','sex','family_client','group_client','music','expirationtime','video_member','other_tv','finance','bank','campus_client','migu_tv','age','adis','arpu_avg','myth_fee_avg','out_prdct_fee_avg','prdct_fee_avg','os','battery_capacity','storage','screen_size']\n",
    "\n",
    "# names = ['id','target','card_type','netlong','owner_city','arpu','out_prdct_fee','prdct_fee','point_fee','myth_fee','brand','listing_date','listing_price','nettime','user_level','sex','family_client','group_client','music','expirationtime','video_member','other_tv','finance','bank','campus_client','migu_tv','age','adis','arpu_avg','myth_fee_avg','out_prdct_fee_avg','prdct_fee_avg']\n",
    "xy_1 = pd.read_table('ZZ0702GuangFa_Samples100000_FeatureData.txt',names=column_name)\n",
    "xy_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('bmh')\n",
    "plt.rc('font',family = 'SimHei',size = 13)\n",
    "#cat_list = ['id','target','card_type','netlong','owner_city','arpu','out_prdct_fee','prdct_fee','point_fee','myth_fee','brand','listing_date','listing_price','nettime','user_level','sex','family_client','group_client','music','expirationtime','video_member','other_tv','finance','bank','campus_client','migu_tv','age','adis','arpu_avg','myth_fee_avg','out_prdct_fee_avg','prdct_fee_avg']\n",
    "cat_list=column_name\n",
    "for n,i in enumerate(cat_list):\n",
    "    xy_1_cat_num = xy_1[i].value_counts().index.shape[0]\n",
    "    print('{0}.{1}特征的类型数量是：{2}'.format(n+1,i,xy_1_cat_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除重复行：\n",
    "xy_1.drop_duplicates(keep='first',inplace=True)\n",
    "xy_1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(xy_1,labels = True)\n",
    "xy_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(xy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据手机上市时间衍生出，上市到现在的累计月份变量listing_data_months\n",
    "#核心代码，转换，array转换成str使用[:]，转换成int加减\n",
    "def month_sept(data):\n",
    "    lst1=[]\n",
    "    for n in range(len(data)):\n",
    "        a=data.loc[n]['listing_date']\n",
    "        if '2019' in str(a):\n",
    "            month_num = str(a)[4:6]\n",
    "            lst1.append(month_num)\n",
    "        elif '2018' in str(a):\n",
    "            month_num = 12-int(str(a)[4:6])+4\n",
    "            lst1.append(month_num)\n",
    "        elif( '2017' in str(a)) and (str(a)!='2017.0'):\n",
    "            month_num = 12-int(str(a)[4:6])+4+12\n",
    "            lst1.append(month_num)\n",
    "        elif '2016' in str(a)and (str(a)!='2016.0'):\n",
    "            month_num = 12-int(str(a)[4:6])+4+24\n",
    "            lst1.append(month_num)\n",
    "        elif '2015' in str(a)and (str(a)!='2015.0'):\n",
    "            month_num = 12-int(str(a)[4:6])+4+36\n",
    "            lst1.append(month_num)\n",
    "        elif '2014' in str(a)and (str(a)!='2014.0'):\n",
    "            month_num = 12-int(str(a)[4:6])+4+48\n",
    "            lst1.append(month_num)\n",
    "        elif '2013' in str(a) and(str(a)!='2013.0'):\n",
    "            month_num = 12-int(str(a)[4:6])+4+60\n",
    "            lst1.append(month_num)\n",
    "    c= pd.concat([xy_1,pd.DataFrame(lst1)],axis=1)\n",
    "    c.rename(columns={0:'listing_data_months'},inplace = True)\n",
    "    return c\n",
    "xy_2 = month_sept(xy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_3 = pd.read_table('city_ranking.txt',names = ['owner_city','owner_city_level'])\n",
    "xy_5 = pd.merge(xy_2,xy_3,on='owner_city',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefulcolumnlist=['target', 'card_type', 'netlong', 'owner_city', 'arpu',\n",
    "       'out_prdct_fee', 'prdct_fee', 'point_fee', 'brand',\n",
    "       'listing_price', 'user_level', 'sex',\n",
    "       'family_client', 'group_client', 'music', \n",
    "       'video_member','finance', 'bank',\n",
    "       'arpu_avg',\n",
    "       'out_prdct_fee_avg', 'prdct_fee_avg', 'battery_capacity',\n",
    "       'storage', 'screen_size', 'listing_data_months', 'owner_city_level']\n",
    "\n",
    "xy_6 = xy_5[usefulcolumnlist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_6[['battery_capacity','storage','screen_size']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_6['battery_capacity'].value_counts()\n",
    "\n",
    "def DealBatteryFormat(RowSeriers):\n",
    "    import re\n",
    "    if RowSeriers.battery_capacity!=RowSeriers.battery_capacity:\n",
    "        return 9999\n",
    "    else:\n",
    "        Battery = RowSeriers.battery_capacity\n",
    "        Batterynum = re.findall('\\d+',Battery)[0]\n",
    "        return int(Batterynum)\n",
    "\n",
    "xy_6['battery_capacity']=xy_6.apply(DealBatteryFormat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_6['battery_capacity'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DealstorageFormat(RowSeriers):\n",
    "    storagestr=str(RowSeriers.storage)\n",
    "   \n",
    "    if 'G' in storagestr:\n",
    "        storagesplit=storagestr.split('/')[0]\n",
    "        if 'G' in storagesplit:\n",
    "            \n",
    "            return storagesplit.split('G')[0]+'GB'\n",
    "        else:            \n",
    "            return storagesplit+'GB'\n",
    "    if 'M' in storagestr:\n",
    "        storagesplit=storagestr.split('/')[0]\n",
    "        if 'M' in storagesplit:\n",
    "            return storagesplit.split('M')[0]+'MB'\n",
    "        else:\n",
    "            return storagesplit+'MB'\n",
    "    else:\n",
    "        return storagestr    \n",
    "\n",
    "xy_6['storage']=xy_6.apply(DealstorageFormat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_6['battery_capacity'].value_counts()/len(xy_6['battery_capacity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_6['finance'].value_counts()\n",
    "xy_6['finance'] = xy_6['finance'].fillna(9999)\n",
    "xy_6['finance'].value_counts()\n",
    "\n",
    "xy_6['bank'].value_counts()\n",
    "xy_6['bank'] = xy_6['bank'].fillna(9999)\n",
    "xy_6['bank'].value_counts()\n",
    "\n",
    "xy_6['owner_city'].value_counts()\n",
    "xy_6['owner_city'] = xy_6['owner_city'].fillna(9999)\n",
    "xy_6['owner_city'].value_counts()\n",
    "\n",
    "xy_6['card_type'].value_counts()\n",
    "xy_6['card_type'] = xy_6['card_type'].fillna(9999)\n",
    "xy_6['card_type'].value_counts()\n",
    "\n",
    "xy_6['netlong'].value_counts()\n",
    "xy_6['netlong'] = xy_6['netlong'].fillna(9999)\n",
    "xy_6['netlong'].value_counts()\n",
    "\n",
    "# arpu 空值填充为999 ，异常值处理\n",
    "xy_6['arpu'].value_counts()\n",
    "xy_6['arpu'].describe()\n",
    "xy_6['arpu'][xy_6['arpu']>500].value_counts()#u+1.5标准差3000\n",
    "#xy_6['arpu'][xy_6['arpu']>500] = 41.82#中位数替换异常值\n",
    "xy_6['arpu'] = xy_6['arpu'].fillna(9999)\n",
    "xy_6['arpu'].value_counts()\n",
    "# arpu_avg\n",
    "xy_6['arpu_avg'].value_counts()#空值填充为999 ，异常值处理\n",
    "xy_6['arpu_avg'].describe()\n",
    "xy_6['arpu_avg'][xy_6['arpu_avg']>3000].value_counts()#u+1.5标准差3000\n",
    "#xy_6['arpu_avg'][xy_6['arpu_avg']>3000] = 43.54#中位数替换异常值\n",
    "xy_6['arpu_avg'] = xy_6['arpu_avg'].fillna(9999)\n",
    "xy_6['arpu_avg'].value_counts()\n",
    "\n",
    "# out_prdct_fee 空值填充为999，异常值处理,Nan没超过30%，按时0值超过了50%，直接构造成（空，0，大于0三类）\n",
    "xy_6['out_prdct_fee'].value_counts()\n",
    "xy_6['out_prdct_fee'].describe()\n",
    "xy_6['out_prdct_fee'][xy_6['out_prdct_fee']>0] = 1\n",
    "xy_6['out_prdct_fee'] = xy_6['out_prdct_fee'].fillna(9999)\n",
    "xy_6['out_prdct_fee'].value_counts()\n",
    "# out_prdct_fee_avg Nan超过30%，直接构造成（空，0，大于0三类）\n",
    "xy_6['out_prdct_fee_avg'].value_counts()\n",
    "xy_6['out_prdct_fee_avg'].describe()\n",
    "xy_6['out_prdct_fee_avg'][xy_6['out_prdct_fee_avg']>0] = 1\n",
    "xy_6['out_prdct_fee_avg'] = xy_6['out_prdct_fee_avg'].fillna(9999)\n",
    "xy_6['out_prdct_fee_avg'].value_counts()\n",
    "\n",
    "# prdct_fee 空值填充为999，异常值处理,Nan没超过30%，加上0值未超过50%，加一层空值999\n",
    "xy_6['prdct_fee'].value_counts()\n",
    "# xy_6 = xy_6.drop(xy_6['prdct_fee'][xy_6['prdct_fee']==0])#删除0值后看剩下的上四分位点加上1.5倍（999-18）=2500\n",
    "# xy_6['prdct_fee'].describe()\n",
    "xy_6['prdct_fee'][xy_6['prdct_fee']>500].value_counts()#中位数替换异常值\n",
    "#xy_6['prdct_fee'][xy_6['prdct_fee']>500] = 23\n",
    "xy_6['prdct_fee'] = xy_6['prdct_fee'].fillna(9999)\n",
    "xy_6['prdct_fee'].value_counts()\n",
    "# prdct_fee_avg空值填充为999，异常值处理,Nan没超过30%，加上0值（7232）未超过50%，加一层空值999\n",
    "xy_6['prdct_fee_avg'].value_counts()\n",
    "# xy_6 = xy_6.drop(xy_6['prdct_fee_avg'][xy_6['prdct_fee_avg']==0])#删除0值后看剩下的上四分位点加上1.5倍（999-18）=2500\n",
    "xy_6['prdct_fee_avg'].describe()\n",
    "xy_6['prdct_fee_avg'][xy_6['prdct_fee_avg']>500].value_counts()#中位数替换异常值\n",
    "#xy_6['prdct_fee_avg'][xy_6['prdct_fee_avg']>500] = 24.6\n",
    "xy_6['prdct_fee_avg'] = xy_6['prdct_fee_avg'].fillna(9999)\n",
    "xy_6['prdct_fee_avg'].value_counts()\n",
    "\n",
    "# point_fee 空值填充为999，异常值处理,Nan没超过30%，加上0值（27824）超过50%，构造（空，0，大于0三类）\n",
    "xy_6['point_fee'].value_counts()\n",
    "xy_6['point_fee'][xy_6['point_fee']>0] = 1\n",
    "xy_6['point_fee'] = xy_6['point_fee'].fillna(9999)\n",
    "xy_6['point_fee'].value_counts()\n",
    "\n",
    "# sex 构造3类\n",
    "xy_6['sex'].value_counts()\n",
    "xy_6['sex'] = xy_6['sex'].fillna(9999)\n",
    "xy_6['sex'].value_counts()\n",
    "\n",
    "# family_client Nan超过30%，构造（空，1两类）\n",
    "xy_6['family_client'].value_counts()\n",
    "xy_6['family_client'] = xy_6['family_client'].fillna(9999)\n",
    "xy_6['family_client'].value_counts()\n",
    "\n",
    "# group_client  Nan超过30%，构造（空，1两类）\n",
    "xy_6['group_client'].value_counts()\n",
    "xy_6['group_client'] = xy_6['group_client'].fillna(9999)\n",
    "xy_6['group_client'].value_counts()\n",
    "\n",
    "# music  Nan超过30%，构造（空，1两类）\n",
    "xy_6['music'].value_counts()\n",
    "xy_6['music'] = xy_6['music'].fillna(9999)\n",
    "xy_6['music'].value_counts()\n",
    "\n",
    "# video_member Nan超过30%，构造（空，1两类）\n",
    "xy_6['video_member'].value_counts()\n",
    "xy_6['video_member'][xy_6['video_member'].notnull()] = 1\n",
    "xy_6['video_member'] = xy_6['video_member'].fillna(9999)\n",
    "xy_6['video_member'].value_counts()\n",
    "\n",
    "\n",
    "# listing_data_months 空值填充为999，异常值处理,Nan没超过30%，加上0值未超过50%，加一层空值999\n",
    "xy_6['listing_data_months'].value_counts()\n",
    "xy_6['listing_data_months'] = xy_6['listing_data_months'].fillna(9999)\n",
    "xy_6['listing_data_months'].value_counts()\n",
    "\n",
    "# user_level  空值填充为999，异常值处理,Nan没超过30%，加上0值未超过50%，加一层空值999\n",
    "xy_6['user_level'].value_counts()\n",
    "xy_6['user_level'] = xy_6['user_level'].fillna(9999)\n",
    "xy_6['user_level'].value_counts()\n",
    "\n",
    "# listing_price 空值填充为999，异常值处理,Nan没超过30%，加上0值（7232）未超过50%，加一层空值999\n",
    "xy_6['listing_price'].value_counts()\n",
    "xy_6['listing_price'] = xy_6['listing_price'].fillna(9999)\n",
    "xy_6['listing_price'].value_counts()\n",
    "\n",
    "# brand 空值填充为999，异常值处理,Nan没超过30%，加上0值（7232）未超过50%，加一层空值999\n",
    "xy_6['brand'].value_counts()\n",
    "xy_6['brand'] = xy_6['brand'].fillna(9999)\n",
    "xy_6['brand'].value_counts()\n",
    "\n",
    "# owner_city_level\n",
    "xy_6['owner_city_level'].value_counts()\n",
    "xy_6['owner_city_level'] = xy_6['owner_city_level'].fillna(9999)\n",
    "xy_6['owner_city_level'].value_counts()\n",
    "#以上，异常值，空值处理完毕\n",
    "\n",
    "xy_6['brand'].value_counts()\n",
    "xy_6['brand'][xy_6['brand']==9999] = '空值'\n",
    "xy_6['brand'][~xy_6['brand'].isin(['vivo','OPPO','苹果','小米','华为','华为荣耀','三星','金立','酷派','魅族','空值'])] ='其它品牌'\n",
    "xy_6['brand'].value_counts()\n",
    "\n",
    "# ['battery_capacity','storage','screen_size']\n",
    "xy_6['battery_capacity'] = xy_6['battery_capacity'].fillna(9999)\n",
    "xy_6['battery_capacity'].value_counts()\n",
    "# xy_6['battery_capacity'][xy_6['battery_capacity']=='nan'] = '空值'\n",
    "# xy_6['battery_capacity'][~xy_6['battery_capacity'].isin(['3000mah','nan','4000mah','1715mah','3050mah','2000mah','1800mah','2750mah','2910mah','1960mah','2900mah','2400mah','3010mah','3100mah','2200mah','2930mah','2850mah','2600mah','2300mah','4100mah','2550mah','3075mah','2500mah','1900mah','2350mah'])] ='其它电池'\n",
    "\n",
    "xy_6['storage'] = xy_6['storage'].fillna('空值')\n",
    "xy_6['storage'][~xy_6['storage'].isin(['nan','16GB','32GB','64GB','8GB','4GB','32MB','128MB','512MB','64MB','128GB','256MB','8MB','4MB','16MB'])] ='其它存储'\n",
    "\n",
    "xy_6['screen_size'] = xy_6['screen_size'].fillna(99)\n",
    "#xy_6['screen_size']=xy_6['screen_size'].astype(str)\n",
    "#xy_6['screen_size'][~xy_6['screen_size'].isin(['5.5','4.7','5','5.2','4','6','5.7','5.8','4.5','5.1','5.9','3.5','空值'])] ='其它屏幕'\n",
    "\n",
    "\n",
    "# #以上，异常值，空值处理完毕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(xy_6,labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(xy_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefulcolumn2=['target','arpu','battery_capacity','brand','card_type','family_client','finance','group_client','listing_data_months','listing_price','music','netlong','out_prdct_fee','out_prdct_fee_avg','owner_city','owner_city_level','prdct_fee','screen_size','sex','storage','user_level','video_member']\n",
    "\n",
    "xy_6=xy_6[usefulcolumn2]\n",
    "\n",
    "xy_6.drop_duplicates(keep='first',inplace=True)\n",
    "xy_6.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in usefulcolumn2:\n",
    "    print(columns,len(xy_6[columns].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#核心代码：遍历版分箱操作\n",
    "def column_binning(data):\n",
    "    column_list = ['arpu','battery_capacity','listing_data_months','listing_price','netlong','prdct_fee']\n",
    "    xy_10 = data\n",
    "    for column in column_list:\n",
    "        print(column)\n",
    "        xy_10.insert(2,column+'_derive_1',xy_10[column])\n",
    "        xy_7 = xy_10[(xy_10[column+'_derive_1'] == 9999) | (xy_10[column+'_derive_1'] == 0)]\n",
    "        xy_8 = xy_10[(0<xy_10[column+'_derive_1'])&(xy_10[column+'_derive_1']<9999)]\n",
    "        xy_8[column+'_derive_1'] = pd.qcut(xy_8[column+'_derive_1'],8)\n",
    "        xy_9 = pd.concat([xy_8,xy_7],axis = 0)\n",
    "        xy_10 = xy_9#循环一次的结果作为下一次循环的开始数据，不能直接给data复制，所以需要有xy_10这个中间变量\n",
    "    return xy_9\n",
    "xy_9=column_binning(xy_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_9.to_excel('20190702广发_信用卡_分箱.xlsx',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_9.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChuanQi_basic_df=xy_9\n",
    "ChuanQi_basic_df=ChuanQi_basic_df[['target', 'prdct_fee_derive_1', 'netlong_derive_1',\n",
    "       'listing_price_derive_1', 'listing_data_months_derive_1',\n",
    "       'battery_capacity_derive_1', 'arpu_derive_1', 'arpu',\n",
    "       'battery_capacity', 'brand', 'card_type', 'family_client', 'finance',\n",
    "       'group_client', 'listing_data_months', 'listing_price', 'music',\n",
    "       'netlong', 'out_prdct_fee', 'out_prdct_fee_avg', 'owner_city',\n",
    "       'owner_city_level', 'prdct_fee', 'screen_size', 'sex', 'storage',\n",
    "       'user_level', 'video_member']]\n",
    "\n",
    "ChuanQi_basic_df.reset_index(inplace=True,drop=True)\n",
    "display(ChuanQi_basic_df.head(),ChuanQi_basic_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DealBrandOPP0(RowSeries):\n",
    "    BrandName=RowSeries.brand\n",
    "    if BrandName in ['OPPO','OPPO ']:\n",
    "        return 'OPPO'\n",
    "    else:\n",
    "        return BrandName\n",
    "ChuanQi_basic_df.brand=ChuanQi_basic_df.apply(DealBrandOPP0,axis=1)\n",
    "\n",
    "brand_group=ChuanQi_basic_df.groupby('target')['brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand_num(ChuanQi_basic_df):\n",
    "    title_mapping = {'苹果':1,'华为':2,'小米':3,'华为荣耀':4,'三星':5,'OPPO':6,'vivo':7,'魅族':8,'金立':9,'酷派':10,'空值':11,'其它品牌':12}\n",
    "    ChuanQi_basic_df['brand'] = ChuanQi_basic_df['brand'].map(title_mapping)\n",
    "brand_num(ChuanQi_basic_df)\n",
    "ChuanQi_basic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#convernetlong_derive_2\tlisting_price_derive_2\n",
    "#interval_list=['listing_data_months_derive_1','prdct_fee_avg_derive_1','arpu_avg_derive_1','prdct_fee_derive_1','listing_price_derive_1','arpu_derive_1','netlong_derive_1']\n",
    "# 传奇游戏特征选择后的连续值：\n",
    "#interval_list=['arpu_derive_1','listing_price','prdct_fee','arpu_avg','prdct_fee_avg','listing_data_months']\n",
    "\n",
    "# 网贷游戏特征选择后的连续变量：\n",
    "interval_list=['prdct_fee_derive_1', 'netlong_derive_1',\n",
    "       'listing_price_derive_1', 'listing_data_months_derive_1',\n",
    "       'battery_capacity_derive_1', 'arpu_derive_1',]\n",
    "# 将区间值列的中间对应值：\n",
    "\n",
    "intervalcolumn_df={}\n",
    "\n",
    "def ConverIntervalData():\n",
    "    for intervalcolumn in interval_list:\n",
    "        ChuanQi_basic_df[intervalcolumn]=ChuanQi_basic_df[intervalcolumn].astype('str')\n",
    "        intervalunique=ChuanQi_basic_df[intervalcolumn].unique()\n",
    "        #print(intervalunique)\n",
    "        intervalcolumn_df[intervalcolumn]={'intervaluniquelist':[]}\n",
    "        intervalcolumn_df[intervalcolumn]['intervaluniquelist']=intervalunique\n",
    "        intervalcolumn_df[intervalcolumn]['intervalValueDict']={}\n",
    "        for intervalValue in intervalunique:\n",
    "            intervalLeft=0.0\n",
    "            intervalRight=0.0\n",
    "            #print(intervalValue)\n",
    "            if ', ' in intervalValue:\n",
    "                intervalValueSplit=intervalValue.split(', ')\n",
    "                intervalLeft=float(intervalValueSplit[0].split('(')[1])\n",
    "                intervalRight=float(intervalValueSplit[1].split(']')[0])\n",
    "                #print(intervalValueSplit,intervalLeft,intervalRight)\n",
    "                intervalcolumn_df[intervalcolumn]['intervalValueDict'][intervalValue]=(intervalRight+intervalLeft)/2\n",
    "            else:\n",
    "                intervalLeft=float(intervalValue)\n",
    "                intervalRight=float(intervalValue)\n",
    "                intervalcolumn_df[intervalcolumn]['intervalValueDict'][intervalValue]=(intervalRight+intervalLeft)/2\n",
    "        \n",
    "        intervalcolumnAvg=[]\n",
    "        for intervalValuekey in intervalcolumn_df[intervalcolumn]['intervalValueDict']:\n",
    "            intervalcolumnAvg.append(intervalcolumn_df[intervalcolumn]['intervalValueDict'][intervalValuekey])\n",
    "        intervalcolumnAvg=np.array(intervalcolumnAvg)\n",
    "        intervalcolumnAvgSortIndex=intervalcolumnAvg.argsort()\n",
    "        maxpointvalue=(intervalcolumnAvg[intervalcolumnAvgSortIndex[-2]]-intervalcolumnAvg[intervalcolumnAvgSortIndex[-3]])/2+intervalcolumnAvg[intervalcolumnAvgSortIndex[-2]]\n",
    "        intervalcolumn_df[intervalcolumn]['intervalValueDict']['9999']=maxpointvalue\n",
    "        #print(intervalcolumnAvg,maxpointvalue)      \n",
    "ConverIntervalData() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将interval 列的数据进行替换操作：\n",
    "\n",
    "def ReplaceIntervalColumnValue():\n",
    "    for intervalcolumn in interval_list:\n",
    "        ChuanQi_basic_df[intervalcolumn].replace(intervalcolumn_df[intervalcolumn]['intervalValueDict'],inplace=True)\n",
    "        #print(a.head(10),ChuanQi_basic_df[intervalcolumn].head(10))\n",
    "ReplaceIntervalColumnValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ChuanQi_basic_df.head(),ChuanQi_basic_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChuanQi_basic_df.to_excel('20190702广发_信用卡_清洗后.xlsx',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifyFeedBack(classifycolumnlist,origindf):\n",
    "    columnvaluecount_dict={}\n",
    "    for classifycolumn in classifycolumnlist:\n",
    "        columngroupvaluecount=origindf.groupby('target')[classifycolumn].value_counts()\n",
    "        columnvaluecount=origindf[classifycolumn].value_counts()\n",
    "        if classifycolumn not in columnvaluecount_dict:            \n",
    "            columnvaluecount_dict[classifycolumn]={}\n",
    "            columnvaluecount_dict[classifycolumn]['target_group']=columngroupvaluecount\n",
    "        columnvaluecount_dict[classifycolumn]['columnvaluecount']=columnvaluecount\n",
    "    return columnvaluecount_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefualcolumns=['target', 'prdct_fee_derive_1', 'netlong_derive_1',\n",
    "       'listing_price_derive_1', 'listing_data_months_derive_1',\n",
    "       'battery_capacity_derive_1', 'arpu_derive_1', 'arpu',\n",
    "       'battery_capacity', 'brand', 'card_type', 'family_client', 'finance',\n",
    "       'group_client', 'listing_data_months', 'listing_price', 'music',\n",
    "       'netlong', 'out_prdct_fee', 'out_prdct_fee_avg', 'owner_city',\n",
    "       'owner_city_level', 'prdct_fee', 'screen_size', 'sex', 'storage',\n",
    "       'user_level', 'video_member']\n",
    "ChuanQi_basic_df=ChuanQi_basic_df[usefualcolumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in usefualcolumns:\n",
    "    print(columns,len(ChuanQi_basic_df[columns].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifycolumnlist=[ 'prdct_fee_derive_1', 'netlong_derive_1',\n",
    "       'listing_price_derive_1', 'listing_data_months_derive_1',\n",
    "       'battery_capacity_derive_1', 'arpu_derive_1',\n",
    "       'brand', 'card_type', 'family_client', 'finance',\n",
    "       'group_client', 'listing_data_months', 'music',\n",
    "       'netlong', 'out_prdct_fee', 'out_prdct_fee_avg', 'owner_city',\n",
    "       'owner_city_level', 'screen_size', 'sex', 'storage',\n",
    "       'user_level', 'video_member']\n",
    "# classifycolumnlist=ChuanQi_basic_df.columns.tolist()\n",
    "# classifycolumnlist.remove('id')\n",
    "# classifycolumnlist.remove('target')\n",
    "columnvaluecount_dict=ClassifyFeedBack(classifycolumnlist,ChuanQi_basic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写个程序检索columnvaluecount_dict 中的不同分类列是否数据一致且要保证相同的特征的不同分区都必须必修要有覆盖，防止分区为空，或者人数为零···\n",
    "\n",
    "def checkmatchCGVC_dict(columnvaluecount_dict):\n",
    "    for column in columnvaluecount_dict:\n",
    "        ColumnAllGroupsIndex=columnvaluecount_dict[column]['columnvaluecount'].index\n",
    "        TureSampleGroupsIndex=columnvaluecount_dict[column]['target_group'][1].index\n",
    "        for GroupsIndex in ColumnAllGroupsIndex:\n",
    "            if GroupsIndex not in TureSampleGroupsIndex: \n",
    "                if GroupsIndex not in columnvaluecount_dict[column]['target_group'][1].index:\n",
    "                    columnvaluecount_dict[column]['target_group'][1,GroupsIndex]=0.00001\n",
    "\n",
    "    return columnvaluecount_dict\n",
    "\n",
    "columnvaluecount_dict=checkmatchCGVC_dict(columnvaluecount_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算正样本的反馈率···\n",
    "import numpy as np\n",
    "def CalculateTurnSampleFeedBack(columnvaluecount_dict):\n",
    "    for column in columnvaluecount_dict:\n",
    "        columnvaluecount_dict[column]['TurnSampleFeedBack']=columnvaluecount_dict[column]['target_group'][1]/columnvaluecount_dict[column]['columnvaluecount']\n",
    "        columnvaluecount_dict[column]['TurnSampleLogPercentRadio']=np.log(columnvaluecount_dict[column]['TurnSampleFeedBack']/(1-columnvaluecount_dict[column]['TurnSampleFeedBack']))\n",
    "    return columnvaluecount_dict\n",
    "\n",
    "columnvaluecount_dict=CalculateTurnSampleFeedBack(columnvaluecount_dict)\n",
    "display(columnvaluecount_dict['brand']['TurnSampleLogPercentRadio'].sort_values(ascending=False),columnvaluecount_dict['brand']['TurnSampleLogPercentRadio'][1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对不同基础属性的类别值（分区）计算row_percent\n",
    "\n",
    "def CalculateColumnRowPercent(columnvaluecount_dict):\n",
    "    for column in columnvaluecount_dict:\n",
    "        columnvaluecount_dict[column]['ColumnRowPercent']=columnvaluecount_dict[column]['columnvaluecount']/columnvaluecount_dict[column]['columnvaluecount'].sum()\n",
    "        \n",
    "    return columnvaluecount_dict\n",
    "\n",
    "columnvaluecount_dict=CalculateColumnRowPercent(columnvaluecount_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每个列的反馈率数值及覆盖率值输出出来···\n",
    "def CreateColumnStatistics(columnvaluecount_dict):\n",
    "    for column in columnvaluecount_dict:\n",
    "        columnvaluecount_dict[column]['ColumnStatistics']=pd.DataFrame({'RowPercent':columnvaluecount_dict[column]['TurnSampleFeedBack'],'Percent':columnvaluecount_dict[column]['ColumnRowPercent']})\n",
    "        \n",
    "    return columnvaluecount_dict\n",
    "\n",
    "columnvaluecount_dict=CreateColumnStatistics(columnvaluecount_dict)\n",
    "len(columnvaluecount_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出分类型变量的反馈率及覆盖率：\n",
    "#ClassifyColumnList=['card_type','owner_city','owner_city_level','brand','user_level','sex','family_client','group_client','music','video_member','out_prdct_fee','out_prdct_fee_avg','point_fee']\n",
    "#ClassifyColumnList=['netlong','card_type','owner_city','brand','user_level','sex','family_client','group_client','music','video_member','owner_city_level','out_prdct_fee','out_prdct_fee_avg','point_fee','other_tv','finance','bank']\n",
    "#ClassifyColumnList=['netlong', 'out_prdct_fee', 'point_fee', 'brand', 'user_level', 'sex', 'family_client', 'group_client', 'owner_city_level']\n",
    "ClassifyColumnList=['prdct_fee_derive_1', 'netlong_derive_1',\n",
    "       'listing_price_derive_1', 'listing_data_months_derive_1',\n",
    "       'battery_capacity_derive_1', 'arpu_derive_1',\n",
    "       'brand', 'card_type', 'family_client', 'finance',\n",
    "       'group_client', 'listing_data_months', 'music',\n",
    "       'netlong', 'out_prdct_fee', 'out_prdct_fee_avg', 'owner_city',\n",
    "       'owner_city_level', 'screen_size', 'sex', 'storage',\n",
    "       'user_level', 'video_member']\n",
    "writer = pd.ExcelWriter('0702广发信用卡模型用户分类变量反馈率统计.xlsx')\n",
    "\n",
    "for ClassifyColumn in ClassifyColumnList:\n",
    "    columnvaluecount_dict[ClassifyColumn]['ColumnStatistics'].to_excel(excel_writer=writer, sheet_name=ClassifyColumn, encoding=\"utf-8\")\n",
    "    #print(ClassifyColumn,columnvaluecount_dict[ClassifyColumn]['ColumnStatistics'])\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "myfont=FontProperties(fname=r'C:\\Windows\\Fonts\\simhei.ttf',size=10)\n",
    "sns.set(font=myfont.get_name())\n",
    "\n",
    "# 对连续型变量的反馈率数据进行绘图操作：\n",
    "ContinuousColumnList=['prdct_fee_derive_1', 'netlong_derive_1',\n",
    "       'listing_price_derive_1', 'listing_data_months_derive_1',\n",
    "       'battery_capacity_derive_1', 'arpu_derive_1',]\n",
    "for ContinuousColumn in ContinuousColumnList:\n",
    "    #print(columnvaluecount_dict[ContinuousColumn]['TurnSampleLogPercentRadio'])\n",
    "    ContinuousSampleLogPercentRadio=pd.DataFrame(columnvaluecount_dict[ContinuousColumn]['TurnSampleLogPercentRadio'])\n",
    "    #print(ContinuousSampleLogPercentRadio.sort_values(by=ContinuousColumn,ascending=False).iloc[1])\n",
    "    ContinuousSampleLogPercentRadio.replace(float('inf'),ContinuousSampleLogPercentRadio.sort_values(by=ContinuousColumn,ascending=False).iloc[1],inplace=True)\n",
    "    ContinuousSampleLogPercentRadio['X_value']=np.log(ContinuousSampleLogPercentRadio.index) #进行对数变换\n",
    "    #ContinuousSampleLogPercentRadio['X_value']=ContinuousSampleLogPercentRadio.index\n",
    "    #print(ContinuousSampleLogPercentRadio,ContinuousSampleLogPercentRadio.columns)\n",
    "    g = sns.FacetGrid(ContinuousSampleLogPercentRadio,palette=\"Set1\", size=7)\n",
    "    g.map(plt.scatter,'X_value',ContinuousColumn,linewidth=.8)\n",
    "    print(ContinuousColumn,ContinuousSampleLogPercentRadio)\n",
    "    g.set_xticklabels(rotation=90)\n",
    "    g.set_axis_labels(ContinuousColumn, \"log(p/1-p)\");\n",
    "    #plt.xlim(1,8)\n",
    "    plt.title(ContinuousColumn+u'(反馈率图形)')\n",
    "    g.add_legend()\n",
    "    g.savefig('广发信用卡模型连续型变量反馈率图像(高消费用户)\\\\'+ContinuousColumn+u'(反馈率图形).png',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('bmh')\n",
    "plt.rc('font',family = 'SimHei',size = 13)\n",
    "cat_list = ['target', 'card_type', 'netlong', 'owner_city', 'arpu',\n",
    "       'out_prdct_fee', 'prdct_fee', 'point_fee', 'myth_fee', 'brand',\n",
    "       'listing_date', 'listing_price', 'nettime', 'user_level', 'sex',\n",
    "       'family_client', 'group_client', 'music', 'expirationtime',\n",
    "       'video_member', 'other_tv', 'finance', 'bank', 'campus_client',\n",
    "       'migu_tv', 'age', 'adis', 'arpu_avg', 'myth_fee_avg',\n",
    "       'out_prdct_fee_avg', 'prdct_fee_avg', 'os', 'battery_capacity',\n",
    "       'storage', 'screen_size']\n",
    "for n,i in enumerate(cat_list):\n",
    "    xy_1_cat_num = xy_1[i].value_counts().index.shape[0]\n",
    "    print('{0}.{1}特征的类型数量是：{2}'.format(n+1,i,xy_1_cat_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChuanQi_basic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 listing_data_months_derive_1，owner_city，listing_data_months\n",
    "\n",
    "xy_1=ChuanQi_basic_df[['target', 'arpu',\n",
    "       'battery_capacity', 'brand', 'card_type', 'family_client', 'finance',\n",
    "       'group_client', 'listing_price', 'music',\n",
    "       'netlong', 'out_prdct_fee', 'out_prdct_fee_avg',\n",
    "       'owner_city_level', 'prdct_fee', 'screen_size', 'sex', 'storage',\n",
    "       'user_level', 'video_member']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(xy_1,labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(xy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in ['target', 'prdct_fee_derive_1', 'netlong_derive_1',\n",
    "       'listing_price_derive_1',\n",
    "       'battery_capacity_derive_1', 'arpu_derive_1', 'arpu',\n",
    "       'battery_capacity', 'brand', 'card_type', 'family_client', 'finance',\n",
    "       'group_client', 'listing_price', 'music',\n",
    "       'netlong', 'out_prdct_fee', 'out_prdct_fee_avg',\n",
    "       'owner_city_level', 'prdct_fee', 'screen_size', 'sex', 'storage',\n",
    "       'user_level', 'video_member']:\n",
    "    print(columns,len(xy_1[columns].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除掉以上列\n",
    "xy_6 = xy_1[['target','arpu','brand','family_client','finance','group_client','listing_price','music','netlong','out_prdct_fee_avg','owner_city_level','prdct_fee','screen_size','sex','storage','user_level','video_member']]\n",
    "\n",
    "# 连续型特征变量：['netlong','arpu','prdct_fee','listing_price','arpu_avg','prdct_fee_avg','screen_size']\n",
    "# 去除重复行：\n",
    "xy_6.drop_duplicates(keep='first',inplace=True)\n",
    "xy_6.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xy_6['netlong'][(xy_6['netlong']==9999)]=58\n",
    "xy_6['netlong'][(xy_6['netlong']==0)]=31\n",
    "\n",
    "xy_6['arpu'][(xy_6['arpu']>400)&(xy_6['arpu']<9999)]=400\n",
    "xy_6['arpu'][(xy_6['arpu']==9999)]=500\n",
    "\n",
    "xy_6['prdct_fee'][(xy_6['prdct_fee']==0)]=70\n",
    "xy_6['prdct_fee'][(xy_6['prdct_fee']>500)&(xy_6['prdct_fee']<9999)]=500\n",
    "xy_6['prdct_fee'][(xy_6['prdct_fee']==9999)]=500\n",
    "\n",
    "xy_6['listing_price'][(xy_6['listing_price']==9999)]=500\n",
    "\n",
    "# xy_6['arpu_avg'][(xy_6['arpu_avg']>500)&(xy_6['arpu_avg']<9999)]=500\n",
    "# xy_6['arpu_avg'][(xy_6['arpu_avg']==9999)]=400\n",
    "\n",
    "# xy_6['prdct_fee_avg'][(xy_6['prdct_fee_avg']>500)&(xy_6['prdct_fee_avg']<9999)]=500\n",
    "# xy_6['prdct_fee_avg'][(xy_6['prdct_fee_avg']==9999)]=400\n",
    "\n",
    "xy_6['screen_size'][(xy_6['screen_size']==99)]=0.37\n",
    "xy_6['screen_size'][~(xy_6['screen_size'].isin([6,5.9,5.7,4.7,5.5,5.2,4.5,4,5,99,2.4,]))]=2\n",
    "\n",
    "# # 电池容量：battery_capacity_derive_1\n",
    "# batterymap={3025:1,5845:1,2875:1,2550:2,3260:2,1850:2,2175:3,7137.5:3,850.4995:3}\n",
    "# xy_6['battery_capacity_derive_1'].replace(batterymap,inplace=True)\n",
    "\n",
    "# 手机品牌：\n",
    "brandmap={1:1,2:2,5:2,6:2,7:3,8:3,4:3,9:3,3:4,10:4,11:4,12:4}\n",
    "xy_6['brand'].replace(brandmap,inplace=True)\n",
    "# xy_6['brand'][(xy_6['brand']==8)|(xy_6['brand']==10)|(xy_6['brand']==6)] = 1000\n",
    "# xy_6['brand'][(xy_6['brand']==11)|(xy_6['brand']==7)|(xy_6['brand']==12)|(xy_6['brand']==4)] = 2000\n",
    "# xy_6['brand'][(xy_6['brand']==9)|(xy_6['brand']==3)|(xy_6['brand']==1)|(xy_6['brand']==2)|(xy_6['brand']==5)] = 3000\n",
    "\n",
    "# user_level\n",
    "userlevelmap={4:1,5:1,6:1,7:1,3:2,9999:3,0:4,1:4,2:4}\n",
    "xy_6['user_level'].replace(userlevelmap,inplace=True)\n",
    "# xy_6['user_level'][(xy_6['user_level']>=5) & (xy_6['user_level']<=7)] =100\n",
    "# xy_6['user_level'][(xy_6['user_level']<=4) | (xy_6['user_level']==9999)] = 200\n",
    "\n",
    "# 内存表：\n",
    "\n",
    "storagemap={'64GB':1,'128GB':1,'32GB':1,'16GB':1,'4GB':2,'8GB':2,'512MB':2,'nan':2,'256MB':3,'128MB':3,'4MB':3,'其它存储':3,'32MB':3,'64MB':3,'16MB':3,'8MB':3}\n",
    "xy_6['storage'].replace(storagemap,inplace=True)\n",
    "\n",
    "# owner_city_level\n",
    "citylevelmap={8:1,9:1,9999:1,7:2,6:2,10:2,1:3,5:3,4:3,3:4,2:4}\n",
    "xy_6['owner_city_level'].replace(citylevelmap,inplace=True)\n",
    "# xy_6['owner_city_level'][xy_6['owner_city_level']>=7] =3\n",
    "# xy_6['owner_city_level'][(xy_6['owner_city_level']>=4) & (xy_6['owner_city_level']<7)] = 2\n",
    "# xy_6['owner_city_level'][xy_6['owner_city_level']<=3] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in [ 'target', 'arpu', 'brand', 'family_client',\n",
    "       'finance', 'group_client', 'listing_price', 'music', 'netlong',\n",
    "       'out_prdct_fee_avg', 'owner_city_level', 'prdct_fee', 'screen_size',\n",
    "       'sex', 'storage', 'user_level', 'video_member']:\n",
    "    print(columns,len(xy_6[columns].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对模型的离散型变量进行虚拟变量处理：onehot编码需要str格式\n",
    "ClassifyColumnsList=['brand', 'family_client',\n",
    "       'finance', 'group_client', 'music', 'out_prdct_fee_avg',\n",
    "       'owner_city_level', 'sex', 'storage', 'user_level',\n",
    "       'video_member']\n",
    "\n",
    "for ClassifyColumn in ClassifyColumnsList:\n",
    "    #print(ClassifyColumn,len(ChuanQi_basic_df[ClassifyColumn].value_counts()))\n",
    "    xy_6[ClassifyColumn]=xy_6[ClassifyColumn].astype('str')\n",
    "xy_7 = xy_6[['target', 'arpu', 'brand', 'family_client', 'finance',\n",
    "       'group_client', 'listing_price', 'music', 'netlong',\n",
    "       'out_prdct_fee_avg', 'owner_city_level', 'prdct_fee', 'screen_size',\n",
    "       'sex', 'storage', 'user_level', 'video_member']]\n",
    "##筛选特定列\n",
    "display(xy_7.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_7_onehot=pd.get_dummies(xy_7)\n",
    "xy_7_onehot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(xy_7_onehot).any()#False表示无缺失值\n",
    "xy_7_onehot[xy_7_onehot.isnull().values==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sm\n",
    "class_weight = dict({1:9,0:1})#配置权重，1万正样本权重为9,9万随机样本的权重为1\n",
    "df_x = xy_7_onehot[[ 'arpu', 'listing_price', 'netlong', 'prdct_fee',\n",
    "       'screen_size', 'brand_1', 'brand_2', 'brand_3', 'brand_4',\n",
    "       'family_client_1.0', 'family_client_9999.0', 'finance_1.0',\n",
    "       'finance_9999.0', 'group_client_1.0', 'group_client_9999.0',\n",
    "       'music_1.0', 'music_9999.0', 'out_prdct_fee_avg_0.0',\n",
    "       'out_prdct_fee_avg_1.0', 'out_prdct_fee_avg_9999.0',\n",
    "       'owner_city_level_1.0', 'owner_city_level_2.0', 'owner_city_level_3.0',\n",
    "       'owner_city_level_4.0', 'sex_0.0', 'sex_1.0', 'sex_9999.0', 'storage_1',\n",
    "       'storage_2', 'storage_3', 'user_level_1.0', 'user_level_2.0',\n",
    "       'user_level_3.0', 'user_level_4.0', 'video_member_1.0',\n",
    "       'video_member_9999.0']]\n",
    "df_y = xy_7_onehot['target']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_x, df_y, test_size=0.5, random_state=0)\n",
    "\n",
    "#逻辑回归\n",
    "model = linear_model.LogisticRegression(class_weight = class_weight)\n",
    "# model = linear_model.Lasso()\n",
    "model.fit(X_train, Y_train)\n",
    "y_train_score = model.decision_function(X_train)#用于计算训练集的KS值\n",
    "y_score = model.decision_function(X_test)#计算预测结果概率值，用于计算测试集的KS值\n",
    "y_test = model.predict(X_test)\n",
    "print('模型预测成功率为：',(y_test == Y_test).sum() / len(y_test))\n",
    "y_test1 = pd.Series(y_test)#**numpy没有value_counts,故要转化为pd.Series.此处是预测值\n",
    "Y_test1 = pd.Series(Y_test)\n",
    "print('真实测试数据：\\n',Y_test1.value_counts())\n",
    "print('预测的测试数据：\\n', y_test1.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegressionCV,LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model.coordinate_descent import ConvergenceWarning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "#对数据的训练集进行标准化\n",
    "ss = StandardScaler()\n",
    "X_StandardScaler = ss.fit(X_train)\n",
    "X_train=X_StandardScaler.transform(X_train)\n",
    "X_test= X_StandardScaler.transform(X_test)\n",
    "# X_train = ss.fit_transform(X_train)     #先拟合数据在进行标准化\n",
    "# X_test = ss.fit_transform(X_test)\n",
    "display(len(X_train),len(X_test))\n",
    "\n",
    "\n",
    "lr = LogisticRegressionCV(multi_class=\"ovr\",fit_intercept=True,Cs=np.logspace(-2,2,20),cv=2,penalty=\"l2\",solver=\"lbfgs\",tol=0.01)\n",
    "\n",
    "re = lr.fit(X_train,Y_train)\n",
    "r_train = re.score(X_train,Y_train)\n",
    "\n",
    "\n",
    "print(\"R值(准确率):\",r_train)\n",
    "print(\"参数:\",re.coef_)\n",
    "print(\"截距:\",re.intercept_)\n",
    "print(\"稀疏化特征比率:%.2f%%\" %(np.mean(lr.coef_.ravel()==0)*100))\n",
    "print(\"=========sigmoid函数转化的值，即：概率p=========\")\n",
    "print(re.predict_proba(X_test)[:5])     #sigmoid函数转化的值，即：概率p\n",
    "\n",
    "\n",
    "Y_test_predict = lr.predict(X_test)      #预测\n",
    "\n",
    "# 计算测试集的准确率···\n",
    "r_test = re.score(X_test,Y_test)\n",
    "print(\"R值(准确率):\",r_test)\n",
    "display(Y_test_predict.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制模型的Roc/Auc值的曲线图\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "lr_y_test_score = lr.decision_function(X_test)\n",
    "lr_fpr_test,lr_tpr_test,lr_threasholds_test = metrics.roc_curve(Y_test.ravel(),lr_y_test_score.ravel())\n",
    "lr_auc_test = metrics.auc(lr_fpr_test,lr_tpr_test)\n",
    "\n",
    "lr_y_train_score = lr.decision_function(X_train)\n",
    "lr_fpr_train,lr_tpr_train,lr_threasholds_train = metrics.roc_curve(Y_train.ravel(),lr_y_train_score.ravel())  #Y_predict\n",
    "lr_auc_train = metrics.auc(lr_fpr_train,lr_tpr_train)\n",
    "\n",
    "\n",
    "print(\"Logistic算法R值(训练):\",lr.score(X_train,Y_train))\n",
    "print(\"Logistic算法AUC值(训练):\",lr_auc_train)\n",
    "\n",
    "print(\"Logistic算法R值(测试):\",lr.score(X_test,Y_test))\n",
    "print(\"Logistic算法AUC值(测试):\",lr_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练集上统计十等分检验表：\n",
    "Y_train_proba=lr.predict_proba(X_train)\n",
    "Y_train_predict=lr.predict(X_train)\n",
    "Y_train_predict_true=Y_train_proba[:,1]\n",
    "\n",
    "Y_test_proba=lr.predict_proba(X_test)\n",
    "Y_test_predict=lr.predict(X_test)\n",
    "Y_test_predict_true=Y_test_proba[:,1]\n",
    "Y_train_predict.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集的十等分表：\n",
    "IndexSeriers=pd.Series(np.arange(0,10,1))\n",
    "\n",
    "\n",
    "Result_KS_10_Dic={'Train_KS_10':{},'Test_KS_10':{}}\n",
    "Result_KS_10_Dic['Train_KS_10']['y_train']=Y_train\n",
    "Result_KS_10_Dic['Train_KS_10']['y_train_predict']=Y_train_predict\n",
    "Result_KS_10_Dic['Train_KS_10']['y_train_true_proba']=Y_train_predict_true\n",
    "Train_KS_10_df=pd.DataFrame(Result_KS_10_Dic['Train_KS_10'])\n",
    "\n",
    "Result_KS_10_Dic['Test_KS_10']['y_test']=Y_test\n",
    "Result_KS_10_Dic['Test_KS_10']['y_test_predict']=Y_test_predict\n",
    "Result_KS_10_Dic['Test_KS_10']['y_test_true_proba']=Y_test_predict_true\n",
    "Test_KS_10_df=pd.DataFrame(Result_KS_10_Dic['Test_KS_10'])\n",
    "display(Train_KS_10_df.head(),len(Train_KS_10_df),Test_KS_10_df.head(),len(Test_KS_10_df))\n",
    "# 对概率值进行降序排列：\n",
    "Train_KS_10_df.sort_values('y_train_true_proba',ascending=False,inplace=True)\n",
    "Train_KS_10_df.reset_index(inplace=True)\n",
    "Train_KS_10_df['true_proba_cluster']=pd.qcut(Train_KS_10_df.y_train_true_proba,10)\n",
    "Result_KS_10_Dic['KS_10_cluster_crowd_number']=pd.DataFrame(Train_KS_10_df.true_proba_cluster.value_counts().sort_index(ascending=False))\n",
    "Result_KS_10_Dic['KS_10_cluster_crowd_number'].reset_index(inplace=True)\n",
    "Result_KS_10_Dic['KS_10_cluster_crowd_number']=pd.concat([Result_KS_10_Dic['KS_10_cluster_crowd_number'],IndexSeriers],axis=1)\n",
    "display(Result_KS_10_Dic['KS_10_cluster_crowd_number'])\n",
    "\n",
    "# 对测试值进行降序排列：\n",
    "Test_KS_10_df.sort_values('y_test_true_proba',ascending=False,inplace=True)\n",
    "Test_KS_10_df.reset_index(inplace=True)\n",
    "Test_KS_10_df['true_proba_cluster']=pd.qcut(Test_KS_10_df.y_test_true_proba,10)\n",
    "Result_KS_10_Dic['Test_KS_10_cluster_crowd_number']=pd.DataFrame(Test_KS_10_df.true_proba_cluster.value_counts().sort_index(ascending=False))\n",
    "Result_KS_10_Dic['Test_KS_10_cluster_crowd_number'].reset_index(inplace=True)\n",
    "Result_KS_10_Dic['Test_KS_10_cluster_crowd_number']=pd.concat([Result_KS_10_Dic['Test_KS_10_cluster_crowd_number'],IndexSeriers],axis=1)\n",
    "display(Result_KS_10_Dic['Test_KS_10_cluster_crowd_number'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算KS_10对应的分层映射值：\n",
    "Result_KS_10_Dic['KS_10_cluster_map']={}\n",
    "for index_number in range(len(Result_KS_10_Dic['KS_10_cluster_crowd_number'])):\n",
    "    Result_KS_10_Dic['KS_10_cluster_map'][Result_KS_10_Dic['KS_10_cluster_crowd_number']['index'][index_number]]=index_number\n",
    "display(Result_KS_10_Dic['KS_10_cluster_map'])\n",
    "\n",
    "# 计算KS_10对应的分层映射值：\n",
    "Result_KS_10_Dic['Test_KS_10_cluster_map']={}\n",
    "for index_number in range(len(Result_KS_10_Dic['Test_KS_10_cluster_crowd_number'])):\n",
    "    Result_KS_10_Dic['Test_KS_10_cluster_map'][Result_KS_10_Dic['Test_KS_10_cluster_crowd_number']['index'][index_number]]=index_number\n",
    "display(Result_KS_10_Dic['Test_KS_10_cluster_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_KS_10_df['true_proba_cluster_map']=Train_KS_10_df['true_proba_cluster'].replace(Result_KS_10_Dic['KS_10_cluster_map'])\n",
    "\n",
    "Test_KS_10_df['true_proba_cluster_map']=Test_KS_10_df['true_proba_cluster'].replace(Result_KS_10_Dic['Test_KS_10_cluster_map'])\n",
    "\n",
    "Train_KS_10_df_groupby_true_proba_cluster_map=Train_KS_10_df.groupby('true_proba_cluster_map')\n",
    "\n",
    "Test_KS_10_df_groupby_true_proba_cluster_map=Test_KS_10_df.groupby('true_proba_cluster_map')\n",
    "\n",
    "Result_KS_10_Dic['KS_10_TPV_Number']={}\n",
    "for proba_cluster_map,proba_cluster_value_df in Train_KS_10_df_groupby_true_proba_cluster_map:\n",
    "    Result_KS_10_Dic['KS_10_TPV_Number'][proba_cluster_map]=(Train_KS_10_df_groupby_true_proba_cluster_map.get_group(proba_cluster_map)['y_train']==1).sum()\n",
    "    \n",
    "Result_KS_10_Dic['Test_KS_10_TPV_Number']={}\n",
    "for proba_cluster_map,proba_cluster_value_df in Test_KS_10_df_groupby_true_proba_cluster_map:\n",
    "    Result_KS_10_Dic['Test_KS_10_TPV_Number'][proba_cluster_map]=(Test_KS_10_df_groupby_true_proba_cluster_map.get_group(proba_cluster_map)['y_test']==1).sum()\n",
    "\n",
    "\n",
    "Result_KS_10_Dic['Real_True_Sample_number']=pd.Series(Result_KS_10_Dic['KS_10_TPV_Number'])\n",
    "Result_KS_10_Dic['Real_True_Sample_number_rate3']=Result_KS_10_Dic['Real_True_Sample_number']/Result_KS_10_Dic['KS_10_cluster_crowd_number']['true_proba_cluster']\n",
    "Result_KS_10_Dic['Real_True_Sample_number_rate4']=pd.Series(Result_KS_10_Dic['Real_True_Sample_number']/np.array(list(Result_KS_10_Dic['KS_10_TPV_Number'].values())).sum())\n",
    "\n",
    "#Result_KS_10_Dic['Test_KS_10_TPV_Number']\n",
    "Result_KS_10_Dic['Test_Real_True_Sample_number']=pd.Series(Result_KS_10_Dic['Test_KS_10_TPV_Number'])\n",
    "Result_KS_10_Dic['Test_Real_True_Sample_number_rate3']=Result_KS_10_Dic['Test_Real_True_Sample_number']/Result_KS_10_Dic['Test_KS_10_cluster_crowd_number']['true_proba_cluster']\n",
    "Result_KS_10_Dic['Test_Real_True_Sample_number_rate4']=pd.Series(Result_KS_10_Dic['Test_Real_True_Sample_number']/np.array(list(Result_KS_10_Dic['Test_KS_10_TPV_Number'].values())).sum())\n",
    "\n",
    "\n",
    "Result_KS_10_Statistics_df=pd.concat([Result_KS_10_Dic['KS_10_cluster_crowd_number']['true_proba_cluster'],Result_KS_10_Dic['Real_True_Sample_number'],Result_KS_10_Dic['Real_True_Sample_number_rate3'],Result_KS_10_Dic['Real_True_Sample_number_rate4']],axis=1)\n",
    "Result_KS_10_Statistics_df.columns=['CustomNumber','True_Sample_CustomNumber','Real_True_Sample_number_rate3','Real_True_Sample_number_rate4']\n",
    "Result_KS_10_Statistics_df['Real_True_Sample_number_rate4_accumulate']=Result_KS_10_Statistics_df['Real_True_Sample_number_rate4'].cumsum()\n",
    "Result_KS_10_Statistics_df['Real_True_Sample_number_rate_random']=np.linspace(0,Result_KS_10_Statistics_df['Real_True_Sample_number_rate4_accumulate'].max(),10)\n",
    "Result_KS_10_Statistics_df['ModelAcquireVaue']=Result_KS_10_Statistics_df['Real_True_Sample_number_rate4_accumulate']-Result_KS_10_Statistics_df['Real_True_Sample_number_rate_random']\n",
    "\n",
    "\n",
    "Result_KS_10_Statistics_Test_df=pd.concat([Result_KS_10_Dic['Test_KS_10_cluster_crowd_number']['true_proba_cluster'],Result_KS_10_Dic['Test_Real_True_Sample_number'],Result_KS_10_Dic['Test_Real_True_Sample_number_rate3'],Result_KS_10_Dic['Test_Real_True_Sample_number_rate4']],axis=1)\n",
    "Result_KS_10_Statistics_Test_df.columns=['Test_CustomNumber','Test_True_Sample_CustomNumber','Test_Real_True_Sample_number_rate3','Test_Real_True_Sample_number_rate4']\n",
    "Result_KS_10_Statistics_Test_df['Test_Real_True_Sample_number_rate4_accumulate']=Result_KS_10_Statistics_Test_df['Test_Real_True_Sample_number_rate4'].cumsum()\n",
    "Result_KS_10_Statistics_Test_df['Test_Real_True_Sample_number_rate_random']=np.linspace(0,Result_KS_10_Statistics_Test_df['Test_Real_True_Sample_number_rate4_accumulate'].max(),10)\n",
    "Result_KS_10_Statistics_Test_df['Test_ModelAcquireVaue']=Result_KS_10_Statistics_Test_df['Test_Real_True_Sample_number_rate4_accumulate']-Result_KS_10_Statistics_Test_df['Test_Real_True_Sample_number_rate_random']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_KS_10_Dic['KS_Point']={'x_point':Result_KS_10_Statistics_df['ModelAcquireVaue'].idxmax(),'y_point':Result_KS_10_Statistics_df['Real_True_Sample_number_rate4_accumulate'][Result_KS_10_Statistics_df['ModelAcquireVaue'].idxmax()]}\n",
    "display(Result_KS_10_Dic['KS_Point'])\n",
    "\n",
    "Result_KS_10_Dic['Test_KS_Point']={'x_point':Result_KS_10_Statistics_Test_df['Test_ModelAcquireVaue'].idxmax(),'y_point':Result_KS_10_Statistics_Test_df['Test_Real_True_Sample_number_rate4_accumulate'][Result_KS_10_Statistics_Test_df['Test_ModelAcquireVaue'].idxmax()]}\n",
    "display(Result_KS_10_Dic['Test_KS_Point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每个箱子中箱子正样本比例Real_True_Sample_number_rate3=True_Sample_CustomNumber/ CustomNumber\n",
    "#箱子正样本占总正样本比例Real_True_Sample_number_rate4=True_Sample_CustomNumber/ΣTrue_Sample_CustomNumber\n",
    "#累计和Real_True_Sample_number_rate4_accumulate=ΣReal_True_Sample_number_rate4\n",
    "display(Result_KS_10_Statistics_df,Result_KS_10_Statistics_Test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显著性分析代码：p>|z|大于0.01的进入模型\n",
    "#AUC（模型稳定性）和KS（区分能力）值计算\n",
    "# Coef. :参数、系数\n",
    "# Std. Err.：系数Coef.的方差的平方根standard error\n",
    "# [95% Conf. Interval] 系数Coef.的95%置信区间\n",
    "# P>|z|: 值小于或等于0.05表示结果显著。 \n",
    "#两个变量协方差分析相关性强，保留Z值绝对值大（显著性强）的那个，如brand和list_price相关性强，就把Z值大的brand2留下\n",
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import auc,roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_x, df_y, test_size=0.5, random_state=0)\n",
    "def stepwise_selection(X, y,\n",
    "                       initial_list=[],\n",
    "                       threshold_in=0.01,\n",
    "                       threshold_out = 0.05,\n",
    "                       verbose = True):\n",
    "    included = list(initial_list)\n",
    " \n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.Logit(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    " \n",
    "        # backward step\n",
    "        model = sm.Logit(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    " \n",
    "result = stepwise_selection(X_train, Y_train)#模板改这里的参数X_train, Y_train\n",
    " \n",
    "print('resulting features:')\n",
    "print(result)\n",
    "\n",
    "lr = sm.Logit(Y_train,sm.add_constant(X_train[result]))\n",
    "rst = lr.fit()\n",
    "print(rst.summary2())\n",
    "\n",
    "y_predicted = rst.predict(sm.add_constant(X_train[result]))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_train,y_predicted, pos_label=1)\n",
    "auc_score = auc(fpr,tpr)\n",
    "w = tpr - fpr\n",
    "ks_score = w.max()\n",
    "ks_x = fpr[w.argmax()]\n",
    "ks_y = tpr[w.argmax()]\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(fpr,tpr,label='AUC=%.5f'%auc_score)\n",
    "ax.set_title('Receiver Operating Characteristic')\n",
    "ax.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6))\n",
    "ax.plot([ks_x,ks_x], [ks_x,ks_y], '--', color='red')\n",
    "ax.text(ks_x,(ks_x+ks_y)/2,'  KS=%.5f'%ks_score)\n",
    "ax.legend()\n",
    "fig.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
